\section{Model architecture and interpretability}
\label{sec:architecture}

\noindent\textit{(Research lead: Necati Deniz Baykuş)}

The research asserts that success depends on an architecture capable of extracting discriminative features from $64\times64$ inputs while staying efficient enough for real-time deployment. A survey of three families—baseline CNNs, ResNet-18, and AlexNet—identified ResNet-18 as the preferred backbone because it balances accuracy with parameter efficiency and distributes attention more evenly across the face, which dovetails with explainability tools that do not rely on single localized regions \cite{talele2024cnnresnet, zhang2024alexnetresnet, reginato2024practical}.

To adapt ResNet-18 for the constrained input size, the original $7\times7$ stride-2 convolution is swapped for a $3\times3$ stride-1 kernel so the receptive field expands cautiously and the low-resolution grid retains horizontal and vertical detail \cite{modi2021resnet}. The downstream four residual stages keep the original Batch Normalisation and ReLU blocks, global average pooling collapses spatial maps, and the final layer is a six-node softmax over happiness, surprise, sadness, anger, disgust, and fear. The same ResNet adjustments also keep parameter counts modest (around 11M), which fits the planned demo use cases.

Hyperparameter exploration showed that a Swish-activated ResNet-18 trained with Adam and CosineAnnealingWarmRestarts produced the strongest testing accuracy, so those elements stay central to the implementation along with the standard regularization techniques already described \cite{pandeya2025resnet}.

Grad-CAM is the explainability tool of choice because preserving spatial structure up to the final pooling simplifies gradient backpropagation, producing saliency maps that highlight semantically meaningful areas (eyes for surprise, mouth for happiness, brows for anger) \cite{selvaraju2017gradcam}. These heatmaps are designed to be overlaid on the live video stream as described elsewhere, providing immediate interpretability.
