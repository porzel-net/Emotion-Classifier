\section{Model architecture and interpretability}
\label{sec:architecture}

\noindent\textit{(Research lead: Necati Deniz Bayku≈ü)}

The architecture chapter synthesizes the decisions described in the model architecture research. We base the classifier on a ResNet-18 backbone because its identity-preserving skip connections make it easier to learn discriminative features from constrained inputs, and the 11M parameter budget keeps inference lightweight for the planned video demo \cite{talele2024cnnresnet, reginato2024practical}. Since the original ResNet is configured for $224\times224$ samples, the initial $7\times7,~\text{stride}=2$ convolution is replaced with a $3\times3,~\text{stride}=1$ kernel so that the receptive field grows more cautiously, preserving horizontal and vertical detail within the $64\times64$ grid \cite{modi2021resnet}. The remaining four residual stages keep their batch normalisation and ReLU activations, followed by global average pooling and a six-node softmax that emits the probabilities for happiness, surprise, sadness, anger, disgust, and fear.

Hyperparameters mirror the research recommendations: Adam ($\beta_1{=}0.9, \beta_2{=}0.999$) is the default optimiser coupled with ReduceLROnPlateau, while SGD with momentum stands ready if a slower, more controlled descent is needed. Weighted cross-entropy compensates for the imbalanced expressions, dropout (0.3) regularises the late blocks, and $L_2$ weight decay keeps magnitudes in check \cite{pandeya2025resnet}. These settings aim for stable learning rather than chasing aggressive fine-tuning results that could overfit to the more frequent classes.

Grad-CAM is the explainability tool of choice because preserving spatial structure up to the final pooling simplifies gradient backpropagation, producing saliency maps that highlight semantically meaningful areas (eyes for surprise, mouth for happiness, brows for anger) \cite{selvaraju2017gradcam}. These heatmaps are designed to be overlaid on the live video stream as described elsewhere, providing immediate interpretability.

\begin{figure}[t]
  \centering
  {
    \setlength{\fboxrule}{0.5pt}
    \setlength{\fboxsep}{2pt}
    \fbox{\includegraphics[width=0.21\linewidth]{resnet18.jpeg}}
  }
  \caption{Adapted ResNet-18 backbone with a smaller initial kernel, residual stages, global average pooling, and six-output softmax tailored to the emotion taxonomy.}
  \label{fig:resnet18}
\end{figure}
